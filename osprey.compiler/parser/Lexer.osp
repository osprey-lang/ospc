use namespace aves;
use namespace osprey.compiler.syntax;

namespace osprey.compiler.parser;

/// Summary: Lexes an Osprey source file, turning it into a sequence of tokens. A lexer's
///          tokens can be accessed by index; however, note that the source file is lexed
///          only on demand. Reading beyond the last token in the file produces a special
///          {Token} with the type {TokenType.eof}.
///
///          The lexer can produce both fatal and recoverable parse errors. A fatal error
///          generally occurs when a token is syntactically malformed, such as a string
///          literal with no terminating quote, or numeric literal with multiple exponential
///          parts. A recoverable error is typically caused by a token that is correctly
///          formed but invalid for other reasons, such as a numeric literal that is out
///          of range.
public class Lexer
{
	/// Summary: Creates a new {Lexer} for the specified {SourceFile}, using the default
	///          flags and an {ErrorManager} that throws all its errors.
	/// Param sourceFile: The {SourceFile} to lex.
	/// Throws ArgumentNullError:
	///          {sourceFile} is null.
	/// Throws ArgumentError:
	///          {sourceFile} is not a {SourceFile}.
	public new(sourceFile)
	{
		new this(sourceFile, LexerFlags.none, null);
	}
	/// Summary: Creates a new {Lexer} for the specified {SourceFile}, using the default
	///          flags and an {ErrorManager} that throws all its errors.
	/// Param sourceFile: The {SourceFile} to lex.
	/// Param flags:      A {LexerFlags} that specifies lexer options.
	/// Throws ArgumentNullError:
	///          {sourceFile} is null.
	/// Throws ArgumentError:
	///          {sourceFile} is not a {SourceFile}.
	///
	///          {flags} is not a {LexerFlags}.
	public new(sourceFile, flags)
	{
		new this(sourceFile, flags, null);
	}
	/// Summary: Creates a new {Lexer} for the specified {SourceFile}, using the specified
	///          flags and {ErrorManager}.
	/// Param sourceFile:   The {SourceFile} to lex.
	/// Param flags:        A {LexerFlags} that specifies lexer options.
	/// Param errorManager: An {ErrorManager} that receives recoverable errors that occur
	///                     during lexing. If this parameter is null, the lexer uses a
	///                     default error manager that throws all errors it receives.
	/// Throws ArgumentNullError:
	///          {sourceFile} is null.
	/// Throws ArgumentError:
	///          {sourceFile} is not a {SourceFile}.
	///
	///          {flags} is not a {LexerFlags}.
	///
	///          {errorManager} is not an {ErrorManager}.
	public new(sourceFile, flags, errorManager)
	{
		if sourceFile is null:
			throw new ArgumentNullError("sourceFile");
		if sourceFile is not SourceFile:
			throw new ArgumentError("sourceFile must be a SourceFile.", "sourceFile");
		if flags is not LexerFlags:
			throw new ArgumentError("flags must be a LexerFlags.", "flags");
		if errorManager is null:
			errorManager = new ParserErrorManager();
		else if errorManager is not ErrorManager:
			throw new ArgumentError("errorManager must be an ErrorManager.", "errorManager");

		this.file = sourceFile;
		this.source = sourceFile.source;
		this.length = this.source.length;
		this.includeComments = flags.hasFlag(LexerFlags.includeComments);
		this.normalizeIdents = flags.hasFlag(LexerFlags.normalizeIdentifiers);
		this.errors = errorManager;
	}

	private file;
	private source;
	private length; // source.length, but cached for speed

	private includeComments; // True to include comments in the token stream
	private normalizeIdents; // True to normalize identifiers

	private sourceIndex = 0;
	private tokens = [];

	private eof; // EOF token if EOF seen, otherwise null

	private lastDocComment; // The last seen documentation comment

	private errors; // ErrorManager

	/// Summary: Gets the {ErrorManager} that the lexer uses.
	public get errorManager = errors;

	/// Summary: Gets the source file that is being lexed.
	public get sourceFile = file;

	public get this[index]
	{
		if ensureMinIndex(index):
			return tokens[index];
		else:
			return eof;
	}

	private ensureMinIndex(index)
	{
		if index < tokens.length:
			return true;
		if eof and index >= tokens.length:
			// We've already determined there are no more tokens to read
			return false;

		while tokens.length <= index + extraTokens:
			if not moveNext():
				break;

		return index < tokens.length;
	}

	private moveNext()
	{
		var tok;
		var i = sourceIndex;
		do
		{
			tok = scanToken(ref i);
		} while not includeComments and tok.type == TokenType.comment;
		sourceIndex = i;

		if lastDocComment
		{
			tok.documentation = lastDocComment;
			lastDocComment = null;
		}

		tokens.add(tok);
		return tok.type != TokenType.eof;
	}

	//<region: Token scanner>

	private scanToken(ref i)
	{
		/* Syntax:
		 *   input:
		 *     input-elements
		 *   input-elements:
		 *     input-element
		 *     input-elements input-element
		 *   input-element:
		 *     whitespace
		 *     comment
		 *     token
		 *   token:
		 *     identifier
		 *     keyword
		 *     integer-literal
		 *     real-literal
		 *     string-literal
		 *     character-literal
		 *     punctuation-token
		 * Additional notes:
		 *   This method skips white space, but does return comments.
		 */

		skipWhiteSpace(ref i);

		if isEOF(i):
			return eof = new Token(getLocation(length, length), TokenType.eof);

		var ch = source[i];
		var nextCh = not isEOF(i + 1) ? source[i + 1] : null;

		if ch == '/' and (nextCh == '/' or nextCh == '*'):
			return scanComment(ref i);

		if ch >= '0' and ch <= '9' or
			ch == '.' and (nextCh is not null and nextCh >= '0' and nextCh <= '9')
		{
			if ch == '0' and (nextCh == 'x' or nextCh == 'X'):
				return scanHexNumber(ref i);
			else:
				return scanDecimalNumber(ref i);
		}

		if ch == '"':
			return scanRegularString(ref i);

		if (ch == 'r' or ch == 'R') and nextCh == '"':
			return scanVerbatimString(ref i);

		if ch == '\'':
			return scanCharLiteral(ref i);

		if isIdentifierStart(ch, i) or
			ch == '\\' and nextCh is not null and isIdentifierStart(nextCh, i + 1):
			return scanIdentifier(ref i);

		return scanPunctuation(ref i);
	}

	private scanComment(ref i)
	{
		/* Syntax:
		 *   comment:
		 *     single-line-comment
		 *     delimited-comment
		 *   single-line-comment:
		 *     '//' input-characters?
		 *   input-characters:
		 *     input-character
		 *     input-characters input-character
		 *   input-character:
		 *     Any Unicode character except a new-line-character
		 *   new-line-character:
		 *     Carriage return character (U+000D)
		 *     Line feed character (U+000A)
		 *     Next line character (U+0085)
		 *     Line separator character (U+2028)
		 *     Paragraph separator character (U+2029)
		 *   delimited-comment:
		 *     '/*' delimited-comment-text? asterisks '/'
		 *   delimited-comment-text:
		 *     delimited-comment-section
		 *     delimited-comment-text delimited-comment-section
		 *   delimited-comment-section:
		 *     '/'
		 *     asterisks? not-slash-or-asterisk
		 *   asterisks:
		 *     '*'
		 *     asterisks '*'
		 *   not-slash-or-asterisk:
		 *     Any Unicode character except '/' or '*'
		 * Additional notes:
		 *   This method also parses documentation comments, which begin with '///'
		 *   or '/**'. When a doc comment starts with '///', this method scans subsequent
		 *   lines for such doc comments as well: each consecutive line that contains
		 *   optional white space followed by a '///' comment is considered part of the
		 *   same doc comment. For example,
		 *
		 *     ///one
		 *     ///two
		 *     ///three
		 *
		 *   would be processed as a single documentation comment with the text
		 *   "///one\n  ///two\n  ///three".
		 */
		var startIndex = i;
		var isMultiline = source[i + 1] == '*';
		i += 2; // Skip "//" or "/*"

		var isDocComment = isMultiline ? isChar(i, '*') : isChar(i, '/');

		if isMultiline
		{
			var foundEnd = false;
			while not isEOF(i)
			{
				var ch = source[i];
				if ch == '*' and isChar(i + 1, '/')
				{
					i += 2; // skip */
					foundEnd = true;
					break;
				}
				else
					i += ch.length;
			}

			if not foundEnd:
				fatalError(ErrorCode.err_DelimitedCommentNotTerminated, startIndex, 2);
		}
		else
		{
			do
			{
				while not isEOF(i)
				{
					var ch = source[i];
					if isNewline(ch):
						break;
					i += ch.length;
				}
				// If we're at EOF or newline, we've found the end of the comment!
				// ... however, if this is a documentation comment, we need to look
				// for the next line as well.
				if isDocComment
				{
					var k = i;
					skipWhiteSpace(ref k);
					if isEOF(k + 2) or source.substring(k, 3) != "///":
						break;
					// If we fall through here, then k + 2 is not past the end and
					// there is a substring "///" at k.
					i = k + 3;
				}
			} while isDocComment;
		}

		var tok = new Token(getLocation(startIndex, i), TokenType.comment);
		if isDocComment:
			lastDocComment = tok;
		// i is now one past the last character in the comment
		return tok;
	}

	private scanDecimalNumber(ref i)
	{
		/* Syntax:
		 *   decimal-integer-literal:
		 *     decimal-value multiplier-suffix? unsigned-suffix?
		 *   decimal-value:
		 *     decimal-digits decimal-digit-sections?
		 *   decimal-digits:
		 *     decimal-digit
		 *     decimal-digits decimal-digit
		 *   decimal-digit: one of
		 *     '0'  '1'  '2'  '3'  '4'  '5'  '6'  '7'  '8'  '9'
		 *   decimal-digit-sections:
		 *     decimal-digit-section
		 *     decimal-digit-sections decimal-digit-section
		 *   decimal-digit-section:
		 *     '_' decimal-digits
		 *   multiplier-suffix: one of
		 *     'k'  'K'  'm'  'M'  'g'  'G'  't'  'T'
		 *   unsigned-suffix: one of
		 *     'u'  'U'
		 *   real-literal:
		 *     decimal-value '.' decimal-digits exponent-part?
		 *     '.' decimal-digits exponent-part?
		 *   exponent-part:
		 *     'e' sign? decimal-digits
		 *     'E' sign? decimal-digits
		 *   sign: one of
		 *     '+'  '-'
		 * Additional notes:
		 *   This method parses both decimal integer literals as well as real literals,
		 *   since they both contain decimal digits in various combinations. The lexer
		 *   decides what type of literal it's dealing with by looking at the presence
		 *   of a decimal point.
		 *
		 *   The method isDigit is technically responsible for parsing the decimal-digit
		 *   symbol, but that symbol is expanded here anyway, for reference.
		 */
		var startIndex = i;

		var emptySection = true; // False if one or more digits encountered after '_'

		var hasDecimals = false; // True if we have decimals
		var hasExp = false; // True if we have an exponential part (...e+123)
		// Note: hasExp implies hasDecimals. It is not possible to have
		// a numeric literal with an exponential part and no decimals.

		while not isEOF(i)
		{
			var ch = source[i];
			if ch == '.' and isDigit(i + 1)
			{
				// Decimals
				if emptySection and startIndex != i:
					fatalError(ErrorCode.err_UnderscoreWithoutDigits, i, 1);
				if hasDecimals:
					fatalError(ErrorCode.err_MultipleDecimalPoints, i, 1);
				hasDecimals = true;
			}
			else if ch == 'e' or ch == 'E'
			{
				if not hasDecimals:
					fatalError(ErrorCode.err_ExponentialPartBeforeDecimalPoint, i, 1);
				if hasExp:
					fatalError(ErrorCode.err_MultipleExponentialParts, i, 1);

				i += 1; // skip e/E

				// The exponential part is followed by an optional sign
				// and one or more digits.
				if not isEOF(i)
				{
					ch = source[i];
					if ch == '+' or ch == '-':
						i += 1;
				}

				if not isDigit(i):
					fatalError(ErrorCode.err_InvalidExponentialPart, i, 1);

				hasExp = true;
				// Keep scanning decimal digits (i += 1 below skips the first one)
			}
			else if ch == '_'
			{
				if hasDecimals:
					fatalError(ErrorCode.err_UnderscoreAfterDecimalPoint, i, 1);
				if emptySection:
					fatalError(ErrorCode.err_MultipleConsecutiveUnderscores, i, 1);
				emptySection = true;
			}
			else if ch < '0' or ch > '9':
				break;
			else:
				emptySection = false;

			i += 1; // All of these are single UTF-16 code units
		}

		if emptySection:
			fatalError(ErrorCode.err_UnderscoreWithoutDigits, i, 1);

		// Everything after this is suffixes.
		var literalEnd = i;

		// I can has multiplier?
		var multiplier = 1;
		if not isEOF(i)
		{
			var ch = source[i];
			if multipliers.tryGet(ch, ref multiplier)
			{
				if hasDecimals:
					fatalError(ErrorCode.err_MultiplierOnReal, i, 1);
				i += 1; // skip multiplier
			}
		}

		// Maybe unsigned suffix?
		var isUnsigned = false;
		if not isEOF(i)
		{
			var ch = source[i];
			if ch == 'u' or ch == 'U'
			{
				if hasDecimals:
					fatalError(ErrorCode.err_UnsignedOnReal, i, 1);
				isUnsigned = true;
				i += 1; // skip u/U
			}
		}

		// Now, let's parse the value!
		var value = source.substringTo(startIndex, literalEnd).replace("_", "");
		var type; // TokenType
		if hasDecimals
		{
			value = Real.parse(value);
			// Infinity = overflow = error condition.
			// NaN is not possible in this situation.
			if value.isInfinite:
				value = null;
			type = TokenType.real;
		}
		else
		{
			type = TokenType.int;
			if isUnsigned:
				value = UInt.parse(value);
			else:
				value = Int.parse(value);

			if value is not null
			{
				try { value *= multiplier; }
				catch OverflowError { value = null; }
			}
		}

		// The parsing can only ever fail due to an overflow. The number is
		// otherwise guaranteed to be in the right format.
		if value is null
		{
			type = hasDecimals ? "Real" :
				isUnsigned ? "UInt" :
				"Int";
			recoverableError(
				ErrorCode.err_NumberOutOfRange,
				[type, source.substringTo(startIndex, i)],
				startIndex, i - startIndex
			);
			value = LiteralToken.invalidValue;
		}

		return new LiteralToken(getLocation(startIndex, i), type, value);
	}

	private scanHexNumber(ref i)
	{
		/* Syntax:
		 *   hexadecimal-integer-literal:
		 *     '0x' hex-value unsigned-suffix?
		 *     '0X' hex-value unsigned-suffix?
		 *   hex-value:
		 *     hex-digits hex-digit-sections?
		 *   hex-digits:
		 *     hex-digit
		 *     hex-digits hex-digit
		 *   hex-digit: one of
		 *     '0'  '1'  '2'  '3'  '4'  '5'  '6'  '7'
		 *     '8'  '9'  'A'  'B'  'C'  'D'  'E'  'F'
		 *     'a'  'b'  'c'  'd'  'e'  'f'
		 *   hex-digit-sections:
		 *     hex-digit-section
		 *     hex-digit-sections hex-digit-section
		 *   hex-digit-section:
		 *     '_' hex-digits
		 *   unsigned-suffix: one of
		 *     'u'  'U'
		 */
		var startIndex = i;
		i += 2; // Skip 0x/0X

		if isEOF(i) or not hexDigits.containsKey(source[i]):
			fatalError(ErrorCode.err_HexNumberWithoutDigits, startIndex, 2);

		var emptySection = true; // False if one or more hex digits encountered after '_'

		// We calculate the hex value while parsing the literal.
		// Use UInt as an intermediate type, because it can fit
		// all the positive values of Int, and literals cannot
		// be negative.
		var value = 0u, overflow = false;
		while not isEOF(i)
		{
			var ch = source[i];
			if ch == '_'
			{
				if emptySection:
					fatalError(ErrorCode.err_MultipleConsecutiveUnderscores, i, 1);
				emptySection = true;
			}
			else
			{
				var digitValue;
				if hexDigits.tryGet(ch, ref digitValue)
				{
					emptySection = false;
					if not overflow
					{
						try { value = value * 16 + digitValue; }
						// If the operation overflows, do keep parsing the literal.
						// That way, we can report the entire literal as the error
						// source, rather than just part of it, which looks better.
						catch OverflowError { overflow = true; }
					}
				}
				else
				{
					break;
				}
			}

			i += 1; // Skip hex digit or underscore
		}

		if emptySection:
			fatalError(ErrorCode.err_UnderscoreWithoutDigits, i, 1);

		var isUnsigned = false;
		if not isEOF(i)
		{
			var ch = source[i];
			if ch == 'u' or ch == 'U'
			{
				isUnsigned = true;
				i += 1; // skip u/U
			}
		}

		if not overflow and not isUnsigned
		{
			try { value = int(value); }
			catch OverflowError { overflow = true; }
		}

		if overflow
		{
			recoverableError(
				ErrorCode.err_NumberOutOfRange,
				[isUnsigned ? "UInt" : "Int", source.substringTo(startIndex, i)],
				startIndex, i - startIndex
			);
			value = LiteralToken.invalidValue;
		}

		return new LiteralToken(
			getLocation(startIndex, i),
			TokenType.int, value
		);
	}

	private scanRegularString(ref i)
	{
		/* Syntax:
		 *   regular-string-literal:
		 *     '"' regular-string-literal-characters? '"'
		 *   regular-string-literal-characters:
		 *     regular-string-literal-character
		 *     regular-string-literal-characters regular-string-literal-character
		 *   regular-string-literal-character:
		 *     single-regular-string-literal-character
		 *     simple-escape-sequence
		 *     unicode-escape-sequence
		 *   single-regular-string-literal-character:
		 *     Any character except '"' (U+0022), '\\' (U+005C) and new-line-character
		 */
		var startIndex = i;
		i += 1; // Skip "

		var sb = new StringBuffer(128);
		var partStart = i;
		var foundEnd = false;
		var hasError = false;
		while not isEOF(i)
		{
			var ch = source[i];
			if ch == '\\'
			{
				// Append any pending characters
				if i > partStart:
					sb.appendSubstring(source, partStart, i - partStart);
				i += 1; // Skip \
				ch = scanEscapeSequence(ref i);
				if ch is null:
					hasError = true;
				else:
					sb.append(ch);
				partStart = i;
			}
			else if ch == '"'
			{
				foundEnd = true;
				break;
			}
			else if isNewline(ch)
			{
				fatalError(ErrorCode.err_NewlineInString, i, 1);
			}
			else
			{
				i += ch.length; // Skip character
			}
		}

		if not foundEnd:
			fatalError(ErrorCode.err_StringNotTerminated, startIndex, 1);

		// Append any pending characters
		if i > partStart:
			sb.appendSubstring(source, partStart, i - partStart);

		i += 1; // Skip "

		return new LiteralToken(
			getLocation(startIndex, i),
			TokenType.string,
			hasError ? LiteralToken.invalidValue : sb.toString()
		);
	}

	private scanVerbatimString(ref i)
	{
		/* Syntax:
		 *   verbatim-string-literal:
		 *     verbatim-string-prefix '"' verbatim-string-literal-characters? '"'
		 *   verbatim-string-prefix: one of
		 *     'r'  'R'
		 *   verbatim-string-literal-characters:
		 *     verbatim-string-literal-character
		 *     verbatim-string-literal-characters verbatim-string-literal-character
		 *   verbatim-string-literal-character:
		 *     single-verbatim-string-literal-character
		 *     quote-escape-sequence
		 *   single-verbatim-string-literal-character:
		 *     Any character except '"'
		 *   quote-escape-sequence:
		 *     '""'
		 */
		var startIndex = i;
		i += 2; // Skip r"/R"

		var foundEnd = false,
			hasEscapes = false;
		while not isEOF(i)
		{
			var ch = source[i];
			i += 1; // Always skip the character
			if ch == '"'
			{
				if not isEOF(i) and source[i] == '"'
				{
					// "" - escape
					i += 1;
					hasEscapes = true;
				}
				else
				{
					foundEnd = true;
					break;
				}
			}
			// Otherwise, it's part of the string!
		}

		if not foundEnd:
			fatalError(ErrorCode.err_StringNotTerminated, startIndex, 2);

		var value = source.substringTo(startIndex + 2, i - 1);
		if hasEscapes:
			// Replace all escapes in one go
			value = value.replace("\"\"", "\"");

		return new LiteralToken(
			getLocation(startIndex, i),
			TokenType.string, value
		);
	}

	private scanCharLiteral(ref i)
	{
		/* Syntax:
		 *   character-literal:
		 *     '\'' literal-character '\''
		 *   literal-character:
		 *     single-literal-character
		 *     simple-escape-sequence
		 *     unicode-escape-sequence
		 *   single-literal-character:
		 *     Any character except '\'' (U+0027), '\\' (U+005C) and new-line-character
		 */
		var startIndex = i;
		i += 1; // Skip '

		var ch;
		if not isEOF(i)
		{
			ch = source.getCharacter(i);
			if ch == '\\'
			{
				i += 1; // Skip \
				ch = scanEscapeSequence(ref i);
			}
			else if isNewline(ch)
			{
				fatalError(ErrorCode.err_NewlineInCharLiteral, i, 1);
			}
			else if ch == '\''
			{
				fatalError(ErrorCode.err_EmptyCharLiteral, i, 1);
			}
			else
			{
				i += ch.length; // Skip character
			}
		}
		if isEOF(i):
			fatalError(ErrorCode.err_CharLiteralNotTerminated, i, 1);
		if source[i] != '\'':
			fatalError(ErrorCode.err_CharLiteralTooLong, i, 1);
		i += 1; // Skip '

		return new LiteralToken(
			getLocation(startIndex, i),
			TokenType.char,
			// If scanEscapeSequence returns null, it's an error.
			// In any other case, ch is a Char
			ch ?? LiteralToken.invalidValue
		);
	}

	private scanEscapeSequence(ref i)
	{
		/* Syntax:
		 *   simple-escape-sequence: one of
		 *     '\\"'  '\\\''  '\\\\'  '\\0'  '\\a'  '\\b'
		 *     '\\n'  '\\r'   '\\t'   '\\_'  '\\-'
		 * Additional notes:
		 *   This method also parses the beginning of unicode escapes, '\\u' or '\\U'.
		 */
		if isEOF(i):
			fatalError(ErrorCode.err_MissingEscapeSequence, i - 1, 1);

		var ch = source[i];
		i += 1; // Skip escaped character

		var escapedChar;
		if not escapes.tryGet(ch, ref escapedChar):
			// If the escape sequence is not found, let escapedChar remain null
			recoverableError(ErrorCode.err_InvalidEscapeSequence, i - 2, 2);
		else if escapedChar is Method:
			escapedChar = escapedChar(this, ref i);

		return escapedChar;
	}

	private scanUnicodeEscape(length, ref i)
	{
		/* Syntax:
		 *   unicode-escape-sequence:
		 *     '\\u' hex-digit hex-digit hex-digit hex-digit
		 *     '\\U' hex-digit hex-digit hex-digit hex-digit
		 *       hex-digit hex-digit hex-digit hex-digit
		 * Additional notes:
		 *   The 'length' parameter is either 4 or 8, depending on the number of
		 *   expected hexadecimal digits. This method does not in itself parse
		 *   the '\\u' or '\\U' part, only the code point.
		 */
		var startIndex = i;

		var expectedLength = length;
		var codePoint = 0;
		while length > 0 and not isEOF(i)
		{
			var digitValue;
			if not hexDigits.tryGet(source[i], ref digitValue):
				fatalError(
					ErrorCode.err_InvalidUnicodeEscapeSequence,
					[expectedLength],
					i, 1
				);

			codePoint = (codePoint << 4) | digitValue;
			length -= 1;
			i += 1;
		}

		if codePoint > 0x10FFFF
		{
			recoverableError(ErrorCode.err_UnicodeEscapeOutOfRange, startIndex, i - startIndex);
			return null;
		}

		return new Char(codePoint);
	}

	private scanIdentifier(ref i)
	{
		/* Syntax:
		 *   identifier:
		 *     An identifier-name that is not a keyword
		 *     '\\' identifier-name
		 *   identifier-name:
		 *     identifier-start-character identifier-part-characters?
		 *   identifier-start-character:
		 *     letter-character
		 *     '_'
		 *   identifier-part-characters:
		 *     identifier-part-character
		 *     identifier-part-characters identifier-part-character
		 *   identifier-part-character:
		 *     letter-character
		 *     A Unicode character of classes Mn, Mc, Nd, Pc or Cf
		 *   letter-character:
		 *     A Unicode character of classes Lu, Ll, Lt, Lm, Lo or Nl
		 * Additional notes:
		 *   An identifier that begins with \ is usually an escaped keyword. The backslash
		 *   is not part of the name when comparing identifiers.
		 *
		 *   This method assumes that it is called with a valid identifier-start-character
		 *   at i, or after the backslash.
		 */
		var startIndex = i;
		var escaped = source[i] == '\\';
		if escaped:
			i += 1; // Skip escape
		var identStart = i;

		var hasFormatChars = false;
		while not isEOF(i)
		{
			var ch = source.getCharacter(i);
			var cat = ch.category;
			if isIdentifierChar(cat):
				i += ch.length;
			else if cat == UnicodeCategory.format
			{
				i += ch.length;
				hasFormatChars = true;
			}
			else
			{
				break;
			}
		}

		var location = getLocation(startIndex, i);
		var ident = source.substringTo(identStart, i);

		// All keywords are valid identifier-names, so unless this identifier is
		// escaped, let's see if it matches a keyword.
		var keywordType;
		if not escaped and ident.length <= longestKeywordLength and
			keywordToType.tryGet(ident, ref keywordType)
		{
			// And if it matches a keyword, it might be a keyword literal
			// (that is, true, false or null).
			var litValue;
			if literalKeywordTypes.tryGet(keywordType, ref litValue):
				return new LiteralToken(location, keywordType, litValue);

			return new Token(location, keywordType, null);
		}

		if normalizeIdents:
			ident = normalizeIdentifier(ident, hasFormatChars);

		return new Identifier(location, ident.intern());
	}

	private scanPunctuation(ref i)
	{
		/* Syntax:
		 *   punctuation-token: one of
		 *     '{'   '}'    '['   ']'   '('    ')'    '.'    ','    ':'   ';'
		 *     '~'   '<'    '<='  '>'   '>='   '=='   '!='   '?'    '??'  '?!'
		 *     '->'  '+'    '-'   '|'   '*'    '/'    '%'    '&'    '^'   '::'
		 *     '<<'  '>>'   '**'  '#'   '$'    '='    '+='   '-='   '|='  '*='
		 *     '/='  '%='   '&='  '^='  '::='  '<<='  '>>='  '**='  '#='  '$='
		 *     '@'   '...'  '?.'  '?('  '?['   '<=>'  '!'
		 */
		var startIndex = i;
		var type = punctuation;
		var ch;
		do
		{
			if isEOF(i) or not type.accepts(ch = source[i], ref type)
			{
				// If this is the first character of the punctuation token,
				// or the PunctInfo's baseType is null, throw an error.
				if i == startIndex or type.baseType is null
				{
					if isEOF(i):
						i -= 1;
					fatalError(
						ErrorCode.err_InvalidCharacter,
						[ch, ch.codePoint.toString("X4")],
						i, 1
					);
				}
				// Otherwise, assign baseType to type; this is the end of
				// the token.
				type = type.baseType;
				break;
			}
			// If we get here, then we're either at EOF, or type.accepts
			// returned true, in which case type is now something else.
			if ch is not null:
				i += 1; // Skip the consumed character
		} while type is PunctInfo;

		return new Token(getLocation(startIndex, i), type);
	}

	private skipWhiteSpace(ref i)
	{
		/* Syntax:
		 *   whitespace:
		 *     Any character with Unicode class Zs
		 *     Horizontal tab character (U+0009)
		 *     Vertical tab character (U+000B)
		 *     Form feed character (U+000C)
		 *     new-line-character
		 */
		while not isEOF(i)
		{
			var ch = source[i];
			if not ch.isWhiteSpace:
				break;
			i += ch.length;
		}
	}

	private fatalError(errorCode, index, length)
	{
		throw new ParseError(
			getErrorToken(index, length),
			errorCode,
			errors.getMessage(errorCode)
		);
	}
	private fatalError(errorCode, formatArg, index, length)
	{
		throw new ParseError(
			getErrorToken(index, length),
			errorCode,
			errors.getMessage(errorCode, formatArg)
		);
	}

	private recoverableError(errorCode, index, length)
	{
		var error = new ParseError(
			getErrorToken(index, length),
			errorCode,
			errors.getMessage(errorCode)
		);
		errors.addError(error);
	}
	private recoverableError(errorCode, formatArg, index, length)
	{
		var error = new ParseError(
			getErrorToken(index, length),
			errorCode,
			errors.getMessage(errorCode, formatArg)
		);
		errors.addError(error);
	}

	private getErrorToken(index, length)
	{
		if isEOF(index):
			return new Token(getLocation(index, index), TokenType.eof, "");
		return new Token(getLocation(index, index + length), TokenType.invalid, null);
	}

	private getLocation(startIndex, endIndex)
	{
		return new SourceLocation(file, startIndex, endIndex);
	}

	private isEOF(i)
	{
		return i >= length;
	}

	private isChar(i, char)
	{
		return not isEOF(i) and source[i] == char;
	}

	private isDigit(i)
	{
		/* Syntax:
		 *   decimal-digit: one of
		 *     '0'  '1'  '2'  '3'  '4'  '5'  '6'  '7'  '8'  '9'
		 */
		if isEOF(i):
			return false;
		var ch = source[i];
		return ch >= '0' and ch <= '9';
	}

	private isIdentifierStart(char, i)
	{
		/* Syntax:
		 *   identifier-start-character:
		 *     letter-character
		 *     '_'
		 *   letter-character:
		 *     A Unicode character of classes Lu, Ll, Lt, Lm, Lo or Nl
		 */
		// UnicodeCategory is all flags, specifically to enable code like this:
		const identifierStartCategories =
			UnicodeCategory.letter |
			UnicodeCategory.letterNumber;
		return char == '_' or
			source.getCategory(i) & identifierStartCategories != UnicodeCategory.none;
	}

	private static isIdentifierChar(category)
	{
		/* Syntax:
		 *   identifier-part-character:
		 *     letter-character
		 *     A Unicode character of classes Mn, Mc, Nd, Pc or Cf
		 *   letter-character:
		 *     A Unicode character of classes Lu, Ll, Lt, Lm, Lo or Nl
		 * Additional notes:
		 *   This method deliberately excludes formatting characters (UnicodeCategory.format),
		 *   because they are tested for separately. Identifier normalization involves
		 *   stripping formatting characters, but almost no identifiers contain formatting
		 *   characters to begin with. Hence, we can improve performance by recording
		 *   separately whether the identifier contains formatting characters, and only
		 *   remove them (which requires a StringBuffer) when they are present.
		 */
		// UnicodeCategory is all flags, specifically to enable code like this:
		const identifierCategories =
			UnicodeCategory.letter |
			UnicodeCategory.decimalNumber |
			UnicodeCategory.letterNumber |
			UnicodeCategory.connectorPunct |
			UnicodeCategory.mark;
		return category & identifierCategories != UnicodeCategory.none;
	}

	private static isNewline(char)
	{
		const newlines = "\u000A\u000D\u0085\u2028\u2029";
		return newlines.contains(char);
	}

	//</region>

	iter
	{
		return new LexerIterator(this);
	}

	//<region: Static members>

	// When trying to read a token, scan up to this number of tokens
	// past the requested index. This somewhat improves performance.
	private const extraTokens = 25;

	private static normalizeIdentifier(ident, hasFormatChars)
	{
		throw new Error("Not implemented");
	}

	/* Syntax:
	 *   keyword: one of
	 *     'abstract'  'and'      'async'      'base'    'break'
	 *     'catch'     'class'    'const'      'do'      'else'
	 *     'enum'      'false'    'finally'    'for'     'function'
	 *     'get'       'global'   'if'         'in'      'inheritable'
	 *     'is'        'iter'     'namespace'  'new'     'next'
	 *     'not'       'null'     'operator'   'or'      'overridable'
	 *     'override'  'private'  'protected'  'public'  'ref'
	 *     'refeq'     'return'   'set'        'static'  'this'
	 *     'throw'     'true'     'try'        'typeof'  'use'
	 *     'var'       'while'    'with'       'xor'     'yield'
	 * Mapping from keyword string to corresponding TokenType.
	 */
	private static keywordToType = {
		"abstract":    TokenType.\abstract,
		"and":         TokenType.\and,
		"async":       TokenType.\async,
		"base":        TokenType.\base,
		"break":       TokenType.\break,
		"catch":       TokenType.\catch,
		"class":       TokenType.\class,
		"const":       TokenType.\const,
		"do":          TokenType.\do,
		"else":        TokenType.\else,
		"enum":        TokenType.\enum,
		"false":       TokenType.\false,
		"finally":     TokenType.\finally,
		"for":         TokenType.\for,
		"function":    TokenType.\function,
		"get":         TokenType.\get,
		"global":      TokenType.\global,
		"if":          TokenType.\if,
		"in":          TokenType.\in,
		"inheritable": TokenType.\inheritable,
		"is":          TokenType.\is,
		"iter":        TokenType.\iter,
		"namespace":   TokenType.\namespace,
		"new":         TokenType.\new,
		"next":        TokenType.\next,
		"not":         TokenType.\not,
		"null":        TokenType.\null,
		"operator":    TokenType.\operator,
		"or":          TokenType.\or,
		"overridable": TokenType.\overridable,
		"override":    TokenType.\override,
		"private":     TokenType.\private,
		"protected":   TokenType.\protected,
		"public":      TokenType.\public,
		"ref":         TokenType.\ref,
		"refeq":       TokenType.\refeq,
		"return":      TokenType.\return,
		"set":         TokenType.\set,
		"static":      TokenType.\static,
		"this":        TokenType.\this,
		"throw":       TokenType.\throw,
		"true":        TokenType.\true,
		"try":         TokenType.\try,
		"typeof":      TokenType.\typeof,
		"use":         TokenType.\use,
		"var":         TokenType.\var,
		"while":       TokenType.\while,
		"with":        TokenType.\with,
		"xor":         TokenType.\xor,
		"yield":       TokenType.\yield,
	};
	// Mapping from TokenType to keyword string. Assigned to by static constructor.
	private static typeToKeyword;

	// Mapping from literal keyword type to corresponding literal value.
	private static literalKeywordTypes = {
		TokenType.\true:  true,
		TokenType.\false: false,
		TokenType.\null:  null,
	};

	// Receives the length of the longest keyword. Assigned to by static constructor.
	private static longestKeywordLength;

	/* Syntax:
	 *   hex-digit: one of
	 *     '0'  '1'  '2'  '3'  '4'  '5'  '6'  '7'
	 *     '8'  '9'  'A'  'B'  'C'  'D'  'E'  'F'
	 *     'a'  'b'  'c'  'd'  'e'  'f'
	 * Mapping from hex-digit to corresponding value (as a UInt).
	 */
	private static hexDigits = {
		'0': 0u,  '1': 1u,  '2': 2u,  '3': 3u,
		'4': 4u,  '5': 5u,  '6': 6u,  '7': 7u,
		'8': 8u,  '9': 9u,  'a': 10u, 'b': 11u,
		'c': 12u, 'd': 13u, 'e': 14u, 'f': 15u,
		'A': 10u, 'B': 11u, 'C': 12u, 'D': 13u,
		'E': 14u, 'F': 15u,
	};

	/* Syntax:
	 *   multiplier-suffix: one of
	 *     'k'  'K'  'm'  'M'  'g'  'G'  't'  'T'
	 * Mapping from multiplier-suffix to corresponding value (as an Int).
	 */
	private static multipliers = {
		'k':             1_024, 'K':             1_024,
		'm':         1_048_576, 'M':         1_048_576,
		'g':     1_073_741_824, 'G':     1_073_741_824,
		't': 1_099_511_627_776, 'T': 1_099_511_627_776,
	};

	/* Syntax:
	 *   simple-escape-sequence: one of
	 *     '\\"'  '\\\''  '\\\\'  '\\0'  '\\a'  '\\b'
	 *     '\\n'  '\\r'   '\\t'   '\\_'  '\\-'
	 *   unicode-escape-sequence:
	 *     '\\u' hex-digit hex-digit hex-digit hex-digit
	 *     '\\U' hex-digit hex-digit hex-digit hex-digit
	 *       hex-digit hex-digit hex-digit hex-digit
	 */
	private static escapes = {
		'0':  '\u0000', // Null
		'a':  '\u0007', // Alert
		'b':  '\u0008', // Backspace
		't':  '\u0009', // Horizontal tab
		'n':  '\u000A', // New line
		'r':  '\u000D', // Carriage return
		'"':  '\u0022', // Double quote
		'\'': '\u0027', // Single quote
		'\\': '\u005C', // Backslash
		'_':  '\u00A0', // No-break space
		'-':  '\u00AD', // Soft hyphen
		'u': @(lexer, ref i) = lexer.scanUnicodeEscape(4, ref i),
		'U': @(lexer, ref i) = lexer.scanUnicodeEscape(8, ref i),
	};

	/* Syntax:
	 *   punctuation-token: one of
	 *     '{'   '}'    '['   ']'   '('    ')'    '.'    ','    ':'   ';'
	 *     '~'   '<'    '<='  '>'   '>='   '=='   '!='   '?'    '??'  '?!'
	 *     '->'  '+'    '-'   '|'   '*'    '/'    '%'    '&'    '^'   '::'
	 *     '<<'  '>>'   '**'  '#'   '$'    '='    '+='   '-='   '|='  '*='
	 *     '/='  '%='   '&='  '^='  '::='  '<<='  '>>='  '**='  '#='  '$='
	 *     '@'   '...'  '?.'  '?('  '?['   '<=>'  '!'
	 */
	private static punctuation = new PunctInfo(null, {
		// Always single: { } [ ] ( ) , ; ~ @
		'{': TokenType.curlyOpen,
		'}': TokenType.curlyClose,
		'[': TokenType.squareOpen,
		']': TokenType.squareClose,
		'(': TokenType.parenOpen,
		')': TokenType.parenClose,
		',': TokenType.comma,
		';': TokenType.semicolon,
		'~': TokenType.tilde,
		'@': TokenType.at,
		'.': new PunctInfo(TokenType.dot, {
			// .. – error
			'.': new PunctInfo(null, {
				// ...
				'.': TokenType.splat,
			}),
		}),
		'<': new PunctInfo(TokenType.less, {
			// <=
			'=': new PunctInfo(TokenType.lessEqual, {
				// <=>
				'>': TokenType.compare,
			}),
			// <<
			'<': PunctInfo.acceptEqual(TokenType.shiftLeft,
				// <<=
				TokenType.shiftLeftAssign),
		}),
		'>': new PunctInfo(TokenType.greater, {
			// >=
			'=': TokenType.greaterEqual,
			// >>
			'>': PunctInfo.acceptEqual(TokenType.shiftRight,
				// >>=
				TokenType.shiftRightAssign),
		}),
		'*': new PunctInfo(TokenType.multiply, {
			// *=
			'=': TokenType.mulAssign,
			// **
			'*': PunctInfo.acceptEqual(TokenType.power,
				// **=
				TokenType.powerAssign),
		}),
		':': new PunctInfo(TokenType.colon, {
			// ::
			':': PunctInfo.acceptEqual(TokenType.concatenate,
				// ::=
				TokenType.concatAssign),
		}),
		'-': new PunctInfo(TokenType.minus, {
			// ->
			'>': TokenType.funcApplication,
			// -=
			'=': TokenType.minusAssign,
		}),
		'+': PunctInfo.acceptEqual(TokenType.plus,
			// +=
			TokenType.plusAssign),
		'|': PunctInfo.acceptEqual(TokenType.pipe,
			// |=
			TokenType.pipeAssign),
		'/': PunctInfo.acceptEqual(TokenType.divide,
			// /=
			TokenType.divAssign),
		'%': PunctInfo.acceptEqual(TokenType.modulo,
			// %=
			TokenType.modAssign),
		'&': PunctInfo.acceptEqual(TokenType.ampersand,
			// &=
			TokenType.ampAssign),
		'^': PunctInfo.acceptEqual(TokenType.caret,
			// ^=
			TokenType.caretAssign),
		'#': PunctInfo.acceptEqual(TokenType.hash,
			// #=
			TokenType.hashAssign),
		'$': PunctInfo.acceptEqual(TokenType.dollar,
			// $=
			TokenType.dollarAssign),
		'=': PunctInfo.acceptEqual(TokenType.assign,
			// ==
			TokenType.doubleEqual),
		'!': PunctInfo.acceptEqual(TokenType.exclam,
			// !=
			TokenType.notEqual),
		'?': new PunctInfo(TokenType.question, {
			// ?.
			'.': TokenType.safeAccess,
			// ?(
			'(': TokenType.parenOpenSafe,
			// ?[
			'[': TokenType.squareOpenSafe,
			// ??
			'?': TokenType.nullCoalescing,
			// ?!
			'!': TokenType.nullOr,
		})
	});

	static new()
	{
		var longestKw = 0;
		typeToKeyword = new Hash(keywordToType.length);
		for kw, type in keywordToType
		{
			typeToKeyword.add(type, kw);
			if kw.length > longestKw:
				longestKw = kw.length;
		}

		longestKeywordLength = longestKw;
	}

	public static getKeywordFromTokenType(type)
	{
		var kw;
		typeToKeyword.tryGet(type, ref kw);
		return kw;
	}

	//</region>
}

// Contains information about a punctuation token. Instances of this class
// may have a base TokenType, and may have zero or more characters that can
// follow the token to create other tokens.
// Examples:
//   * '<' has TokenType.less, can be followed by '<' to make TokenType.shiftLeft,
//     or by '=' to make TokenType.lessEqual, which in turn can be followed by '>'
///    to make TokenType.compare.
//   * '.' has TokenType.dot, can be followed by '.' which has no base token type, which
//     can be followed by another '.' to make TokenType.splat.
//   * '*' has TokenType.multiply, and can be followed by '=' to make TokenType.mulAssign
//     or by '*' to make TokenType.power.
//
// When a PunctInfo has no base type, it means the particular sequence of characters that
// led to the PunctInfo are invalid without another character following.
private class PunctInfo
{
	public new(this._baseType, this._nextChars);

	private _baseType;
	// The base TokenType of the punctuation token, or null if it must
	// be followed by something.
	public get baseType = _baseType;

	private _nextChars;

	public accepts(nextChar, ref nextType)
	{
		return _nextChars.tryGet(nextChar, ref nextType);
	}

	public static acceptEqual(baseType, equalType)
	{
		return new PunctInfo(baseType, {'=': equalType});
	}
}

private class LexerIterator is Iterator
{
	public new(this.lexer);

	private lexer;
	private index = 0;
	private _current = null;

	override get current = _current;

	override moveNext()
	{
		var tok = lexer[index];
		if tok.type != TokenType.eof
		{
			_current = tok;
			index += 1;
			return true;
		}

		_current = null;
		return false;
	}
}
