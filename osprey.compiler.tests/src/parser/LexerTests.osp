use aves.*;
use testing.unit.*;
use osprey.compiler.tests.*;
use osprey.compiler.parser.{
	TokenType as TT, // For brevity in some long lists
	ContextualType as CT, // Also for brevity
};

namespace osprey.compiler.parser.tests;

public class LexerTests is TestFixture
{
	public new() { new base("osprey.compiler.parser.Lexer tests"); }

	private errors = new TestErrorManager();

	override setUp()
	{
		errors.clearAll();
	}

	// Constructor tests

	public test_Constructor1()
	{
		var file = SourceFile.createAnon("");
		var lexer;
		Assert.doesNotThrow(@{ lexer = new Lexer(file); });
		Assert.areSameRef(file, lexer.sourceFile);
	}

	public test_Constructor1WithInvalidFile()
	{
		Assert.throws(typeof(ArgumentTypeError), @=> new Lexer(""));
		Assert.throws(typeof(ArgumentNullError), @=> new Lexer(null));
	}

	public test_Constructor2()
	{
		var file = SourceFile.createAnon("");
		var lexer;
		Assert.doesNotThrow(@{ lexer = new Lexer(file, LexerFlags.none); });
		Assert.areSameRef(file, lexer.sourceFile);
	}

	public test_Constructor2WithInvalidFile()
	{
		Assert.throws(typeof(ArgumentTypeError), @=> new Lexer("", LexerFlags.none));
		Assert.throws(typeof(ArgumentNullError), @=> new Lexer(null, LexerFlags.none));
	}

	public test_Constructor2WithInvalidFlags()
	{
		var file = SourceFile.createAnon("");
		Assert.throws(typeof(ArgumentTypeError), @=> new Lexer(file, 0));
		Assert.throws(typeof(ArgumentTypeError), @=> new Lexer(file, "none"));
	}

	public test_Constructor3()
	{
		var file = SourceFile.createAnon("");
		var errors = new TestErrorManager();
		var lexer;
		Assert.doesNotThrow(@{ lexer = new Lexer(file, LexerFlags.none, errors); });
		Assert.areSameRef(file, lexer.sourceFile);
		Assert.areSameRef(errors, lexer.errorManager);
	}

	public test_Constructor3WithNullErrorManager()
	{
		// When the ErrorManager is null, the lexer creates its own.
		var file = SourceFile.createAnon("");
		var lexer;
		Assert.doesNotThrow(@{ lexer = new Lexer(file, LexerFlags.none, null); });
		Assert.areSameRef(file, lexer.sourceFile);
		Assert.isNotNull(lexer.errorManager);
	}

	public test_Constructor3WithInvalidFile()
	{
		var errors = new TestErrorManager();
		Assert.throws(typeof(ArgumentTypeError), @=> new Lexer("", LexerFlags.none, errors));
		Assert.throws(typeof(ArgumentNullError), @=> new Lexer(null, LexerFlags.none, errors));
	}

	public test_Constructor3WithInvalidFlags()
	{
		var file = SourceFile.createAnon("");
		var errors = new TestErrorManager();
		Assert.throws(typeof(ArgumentTypeError), @=> new Lexer(file, 0, errors));
		Assert.throws(typeof(ArgumentTypeError), @=> new Lexer(file, "none", errors));
	}

	public test_Constructor3WithInvalidErrorManager()
	{
		var file = SourceFile.createAnon("");
		Assert.throws(typeof(ArgumentTypeError), @=> new Lexer(file, LexerFlags.none, "Not an ErrorManager"));
	}

	// Actual lexing tests!

	// Helper method for creating a Lexer.
	private lex(source, flags = LexerFlags.none)
	{
		var file = SourceFile.createAnon(source);
		return new Lexer(file, flags, errors);
	}

	private assertTokenMatches(token, type)
	{
		Assert.areEqual(token.type, type);
		return true;
	}

	private assertTokenMatches(token, type, sourceText)
	{
		Assert.areEqual(token.type, type);
		Assert.areEqual(token.sourceText, sourceText);
		return true;
	}

	private assertErrorsMatch(errorCodes)
	{
		Assert.collectionsMatch(
			errors.getAllErrors(),
			errorCodes,
			@(error, code) => Assert.areEqual(error.errorCode, code)
		);
	}

	private assertThrowsParseError(source, errorCode)
	{
		var lexer = lex(source);
		var error = Assert.throws(typeof(ParseError), @=> lexer[0]);
		Assert.areEqual(error.errorCode, errorCode);
	}

	private assertIsEOF(token)
	{
		assertTokenMatches(token, TokenType.eof);
		return true;
	}

	public test_LineComment1()
	{
		var source = "//comment";
		var lexer = lex(source, LexerFlags.includeComments);
		assertTokenMatches(lexer[0], TokenType.comment, source);
		assertIsEOF(lexer[1]);
	}

	public test_LineComment2()
	{
		var lexer = lex("//comment 1\t\n//comment 2  \n", LexerFlags.includeComments);
		// The comments should not contain the newlines, but should
		// contain the trailing white space.
		assertTokenMatches(lexer[0], TokenType.comment, "//comment 1\t");
		assertTokenMatches(lexer[1], TokenType.comment, "//comment 2  ");
		assertIsEOF(lexer[2]);
	}

	public test_LineDocComment1()
	{
		var lexer = lex("///doc comment", LexerFlags.includeComments);
		assertTokenMatches(lexer[0], TokenType.comment, "///doc comment");
		assertIsEOF(lexer[1]);
	}

	public test_LineDocComment2()
	{
		var source = "///doc comment line 1\n///doc comment line 2";
		var lexer = lex(source, LexerFlags.includeComments);
		// The lexer DOES include all the lines of a doc comment, verbatim.
		assertTokenMatches(lexer[0], TokenType.comment, source);
		assertIsEOF(lexer[1]);
	}

	public test_PunctuationGeneral()
	{
		var source = r".  ,  :  ;  @  ...  ?.  !";
		var lexer = lex(source);

		var tokens = [
			TT.dot, TT.comma,
			TT.colon, TT.semicolon,
			TT.at, TT.splat,
			TT.safeAccess, TT.exclam,
		];

		Assert.collectionsMatch(lexer, tokens, assertTokenMatches);
	}

	public test_PunctuationBrackets()
	{
		var source = r"{  }  [  ]  (  )  ?(  ?[";
		var lexer = lex(source);

		// Same order as the source, of course. Sorry it's a bit hard to read.
		var tokens = [
			TT.curlyOpen, TT.curlyClose,
			TT.squareOpen, TT.squareClose,
			TT.parenOpen, TT.parenClose,
			TT.parenOpenSafe, TT.squareOpenSafe,
		];

		Assert.collectionsMatch(lexer, tokens, assertTokenMatches);
	}

	public test_PunctuationOperators()
	{
		var source = r"
			~   <   <=  >  >=  ==   !=  ?  ??  ?!
			->  +   -   |  *   /    %   &  ^   ::
			<<  >>  **  <=>  =>
		";
		var lexer = lex(source);

		// Same order as the source, of course. Sorry it's a bit hard to read.
		var tokens = [
			TT.tilde,
			TT.less, TT.lessEqual, TT.greater, TT.greaterEqual,
			TT.doubleEqual, TT.notEqual, TT.question,
			TT.nullCoalescing, TT.nullOr,
			TT.funcApplication, TT.plus, TT.minus, TT.pipe,
			TT.multiply, TT.divide, TT.modulo, TT.ampersand,
			TT.caret, TT.concatenate, TT.shiftLeft, TT.shiftRight,
			TT.power, TT.compare, TT.fatArrow,
		];

		Assert.collectionsMatch(lexer, tokens, assertTokenMatches);
	}

	public test_PunctuationAssignOperators()
	{
		var source = r"=  +=  -=  |=  *=  /=  %=  &=  ^=  ::=  <<=  >>=  **=";
		var lexer = lex(source);

		// Same order as the source, of course. Sorry it's a bit hard to read.
		var tokens = [
			TT.assign,
			TT.plusAssign, TT.minusAssign, TT.pipeAssign,
			TT.mulAssign, TT.divAssign, TT.modAssign, TT.ampAssign,
			TT.caretAssign, TT.concatAssign,
			TT.shiftLeftAssign, TT.shiftRightAssign,
			TT.powerAssign,
		];

		Assert.collectionsMatch(lexer, tokens, assertTokenMatches);
	}

	public test_Keywords()
	{
		var source = r"
			abstract     and       async    base         break
			catch        class     const    do           else
			enum         false     finally  for          function
			global       if        in       inheritable  internal
			is           iter      let      namespace    new
			next         not       null     operator     or
			overridable  override  private  protected    public
			ref          refeq     return   static       this
			throw        true      try      typeof       use
			var          while     with     xor          yield
		";
		var lexer = lex(source);

		// Same order as the source, of course. Sorry it's a bit hard to read.
		var tokens = [
			TT.\abstract,    TT.\and,      TT.\async,   TT.\base,        TT.\break,
			TT.\catch,       TT.\class,    TT.\const,   TT.\do,          TT.\else,
			TT.\enum,        TT.\false,    TT.\finally, TT.\for,         TT.\function,
			TT.\global,      TT.\if,       TT.\in,      TT.\inheritable, TT.\internal,
			TT.\is,          TT.\iter,     TT.\let,     TT.\namespace,   TT.\new,
			TT.\next,        TT.\not,      TT.\null,    TT.\operator,    TT.\or,
			TT.\overridable, TT.\override, TT.\private, TT.\protected,   TT.\public,
			TT.\ref,         TT.\refeq,    TT.\return,  TT.\static,      TT.\this,
			TT.\throw,       TT.\true,     TT.\try,     TT.\typeof,      TT.\use,
			TT.\var,         TT.\while,    TT.\with,    TT.\xor,         TT.\yield,
		];

		Assert.collectionsMatch(lexer, tokens, assertTokenMatches);
	}

	public test_KeywordEscapes()
	{
		var source = r"
			\abstract     \and       \async    \base         \break
			\catch        \class     \const    \do           \else
			\enum         \false     \finally  \for          \function
			\global       \if        \in       \inheritable  \internal
			\is           \iter      \let      \namespace    \new
			\next         \not       \null     \operator     \or
			\overridable  \override  \private  \protected    \public
			\ref          \refeq     \return   \static       \this
			\throw        \true      \try      \typeof       \use
			\var          \while     \with     \xor          \yield
		";
		var lexer = lex(source);

		var count = 0;
		for token in lexer {
			Assert.areEqual(token.type, TT.identifier);
			Assert.areEqual(token.contextualType, CT.none);
			count += 1;
		}
		Assert.areEqual(count, 50);
	}

	public test_ContextualKeywords()
	{
		var source = r"
			as  get  set
			__primitive  __init_type  __extern
			__named_const
		";
		var lexer = lex(source);

		// Same order as the source, of course.
		var tokens = [
			CT.as, CT.get, CT.set,
			CT.primitive, CT.initType, CT.extern,
			CT.namedConst
		];

		Assert.collectionsMatch(lexer, tokens, @(token, contextualType) {
			Assert.areEqual(token.type, TT.identifier);
			Assert.isOfType(token, typeof(Identifier));
			Assert.areEqual(token.contextualType, contextualType);
			return true;
		});
	}

	public test_ContextualKeywordEscapes()
	{
		var source = r"
			\as  \get  \set
			\__primitive  \__init_type  \__extern
			\__named_const
		";
		var lexer = lex(source);

		var count = 0;
		for token in lexer {
			Assert.areEqual(token.type, TT.identifier);
			Assert.isOfType(token, typeof(Identifier));
			Assert.areEqual(token.contextualType, CT.none);
			count += 1;
		}
		Assert.areEqual(count, 7);
	}

	public test_SimpleDecimalIntegerLiteral()
	{
		var source = r"
			1   12345678   2147483647    9223372036854775807
			1u  12345678u  4294967295u  18446744073709551615u
		";
		var lexer = lex(source);

		var values = [
			1,  12345678,  2147483647,   9223372036854775807,
			1u, 12345678u, 4294967295u, 18446744073709551615u,
		];

		Assert.collectionsMatch(lexer, values, @(token, value) {
			assertTokenMatches(token, TT.int);
			Assert.areSameRef(token.literalValue, value);
			return true;
		});
	}

	public test_DecimalIntegerLiteralWithThousandsSeparator()
	{
		// Thousands separator can be between any pair of digits
		var source = r"
			1   12_345_678   2147_483_64_7    92_23_3_72_036_8547_75807
			1u  12_345_678u  4294_967_29_5u  184_46_7_44_073_7095_51615u
		";
		var lexer = lex(source);

		var values = [
			1,  12345678,  2147483647,   9223372036854775807,
			1u, 12345678u, 4294967295u, 18446744073709551615u,
		];

		Assert.collectionsMatch(lexer, values, @(token, value) {
			assertTokenMatches(token, TT.int);
			Assert.areSameRef(token.literalValue, value);
			return true;
		});
	}

	public test_SignedDecimalIntegerLiteralOutOfRange()
	{
		var source = r"123_456_789_012_345_678_901_234_567_890";
		var lexer = lex(source);

		// The token type should be int, but the value is invalid
		var token = lexer[0];
		assertTokenMatches(token, TT.int);
		Assert.areSameRef(token.literalValue, LiteralToken.invalidValue);
		assertErrorsMatch([ErrorCode.err_NumberOutOfRange]);
		assertIsEOF(lexer[1]);
	}

	public test_UnsignedDecimalIntegerLiteralOutOfRange()
	{
		var source = r"123_456_789_012_345_678_901_234_567_890u";
		var lexer = lex(source);

		// The token type should be int, but the value is invalid
		var token = lexer[0];
		assertTokenMatches(token, TT.int);
		Assert.areSameRef(token.literalValue, LiteralToken.invalidValue);
		assertErrorsMatch([ErrorCode.err_NumberOutOfRange]);
		assertIsEOF(lexer[1]);
	}

	public test_InvalidDecimalInteger()
	{
		assertThrowsParseError(r"123__456", ErrorCode.err_MultipleConsecutiveUnderscores);
		assertThrowsParseError(r"123_", ErrorCode.err_UnderscoreWithoutDigits);
	}
}
